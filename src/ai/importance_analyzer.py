#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–°é—»é‡è¦ç¨‹åº¦åˆ†æå™¨

ä½¿ç”¨DeepSeekæ€è€ƒæ¨¡å‹åˆ†ææ–°é—»çš„é‡è¦ç¨‹åº¦ï¼Œè¯„åˆ†èŒƒå›´0-100åˆ†
"""

import json
import time
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional, Union
import re

from openai import OpenAI
import yaml

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

try:
    from src.utils.database import NewsItem
    from src.utils.logger import get_logger
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥é¡¹ç›®æ¨¡å—ï¼Œä½¿ç”¨ç›¸å¯¹å¯¼å…¥
    from ..utils.database import NewsItem
    from ..utils.logger import get_logger

logger = get_logger("importance_analyzer")


@dataclass
class ImportanceResult:
    """é‡è¦ç¨‹åº¦åˆ†æç»“æœ"""
    news_id: str
    title: str
    importance_score: int  # 0-100åˆ†
    reasoning: str  # åˆ†ææ¨ç†è¿‡ç¨‹
    key_factors: List[str]  # å½±å“é‡è¦ç¨‹åº¦çš„å…³é”®å› ç´ 
    analysis_time: str
    model_used: str


class ImportanceAnalyzer:
    """æ–°é—»é‡è¦ç¨‹åº¦åˆ†æå™¨"""
    
    def __init__(self, config: Dict = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config or self._load_config()
        self.client = None
        self._init_client()
        
    def _load_config(self) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        import os
        config_path = os.path.join(
            os.path.dirname(__file__), "../../config/config.yaml"
        )
        
        try:
            with open(config_path, "r", encoding="utf-8") as f:
                return yaml.safe_load(f) or {}
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return {}
    
    def _init_client(self):
        """åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯"""
        try:
            deepseek_config = self.config.get("ai_analysis", {}).get("deepseek", {})
            
            if not deepseek_config.get("api_key"):
                logger.warning("æœªé…ç½®DeepSeek APIå¯†é’¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
                self.client = None
                return
            
            self.client = OpenAI(
                api_key=deepseek_config.get("api_key"),
                base_url=deepseek_config.get("base_url", "https://api.deepseek.com/v1")
            )
            
            logger.info("DeepSeekæ€è€ƒæ¨¡å‹APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯å¤±è´¥: {e}")
            self.client = None
    
    def analyze_importance(self, news_item: NewsItem) -> ImportanceResult:
        """
        åˆ†æå•æ¡æ–°é—»çš„é‡è¦ç¨‹åº¦
        
        Args:
            news_item: æ–°é—»é¡¹
            
        Returns:
            ImportanceResult: é‡è¦ç¨‹åº¦åˆ†æç»“æœ
        """
        if self.client is None:
            return self._mock_analysis(news_item)
        
        try:
            # æ„å»ºåˆ†æprompt
            prompt = self._build_importance_prompt(news_item)
            
            # è°ƒç”¨æ€è€ƒæ¨¡å‹
            response = self._call_thinking_model(prompt)
            
            # è§£æç»“æœ
            result = self._parse_importance_result(news_item, response)
            
            logger.info(f"å®Œæˆæ–°é—»é‡è¦ç¨‹åº¦åˆ†æ: {news_item.title[:50]}... -> {result.importance_score}åˆ†")
            
            return result
            
        except Exception as e:
            logger.error(f"åˆ†ææ–°é—»é‡è¦ç¨‹åº¦å¤±è´¥: {e}")
            return self._mock_analysis(news_item, error=True)
    
    def batch_analyze_importance(self, news_list: List[NewsItem]) -> List[ImportanceResult]:
        """
        æ‰¹é‡åˆ†ææ–°é—»é‡è¦ç¨‹åº¦
        
        Args:
            news_list: æ–°é—»åˆ—è¡¨
            
        Returns:
            List[ImportanceResult]: é‡è¦ç¨‹åº¦åˆ†æç»“æœåˆ—è¡¨
        """
        results = []
        total = len(news_list)
        
        logger.info(f"å¼€å§‹æ‰¹é‡é‡è¦ç¨‹åº¦åˆ†æï¼Œå…± {total} æ¡æ–°é—»")
        
        for i, news_item in enumerate(news_list, 1):
            try:
                result = self.analyze_importance(news_item)
                results.append(result)
                
                logger.info(f"è¿›åº¦: {i}/{total} - {result.importance_score}åˆ†")
                
                # æ·»åŠ å»¶æ—¶é¿å…APIé™åˆ¶
                if i < total and self.client is not None:
                    time.sleep(1)
                    
            except Exception as e:
                logger.error(f"åˆ†æç¬¬{i}æ¡æ–°é—»å¤±è´¥: {e}")
                # æ·»åŠ é”™è¯¯å ä½ç»“æœ
                error_result = self._mock_analysis(news_item, error=True)
                results.append(error_result)
        
        logger.info(f"æ‰¹é‡é‡è¦ç¨‹åº¦åˆ†æå®Œæˆï¼Œå…±åˆ†æ {len(results)} æ¡æ–°é—»")
        return results
    
    def _build_importance_prompt(self, news_item: NewsItem) -> str:
        """æ„å»ºé‡è¦ç¨‹åº¦åˆ†æçš„prompt"""
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹è´¢ç»æ–°é—»çš„é‡è¦ç¨‹åº¦ï¼Œå¹¶ç»™å‡º0-100åˆ†çš„è¯„åˆ†ã€‚

æ–°é—»ä¿¡æ¯ï¼š
- æ ‡é¢˜ï¼š{news_item.title}
- å†…å®¹ï¼š{news_item.content}
- æ¥æºï¼š{news_item.source}
- åˆ†ç±»ï¼š{news_item.category}
- å‘å¸ƒæ—¶é—´ï¼š{news_item.publish_time}

è¯„åˆ†æ ‡å‡†ï¼š
- 90-100åˆ†ï¼šæå…¶é‡è¦ï¼Œå¯èƒ½å¼•å‘å¸‚åœºå‰§çƒˆæ³¢åŠ¨çš„é‡å¤§äº‹ä»¶
- 80-89åˆ†ï¼šå¾ˆé‡è¦ï¼Œå¯¹å¸‚åœºæœ‰æ˜¾è‘—å½±å“çš„é‡è¦æ¶ˆæ¯
- 70-79åˆ†ï¼šé‡è¦ï¼Œå¯¹ç›¸å…³è¡Œä¸šæˆ–æ¿å—æœ‰æ˜æ˜¾å½±å“
- 60-69åˆ†ï¼šä¸­ç­‰é‡è¦ï¼Œæœ‰ä¸€å®šå¸‚åœºå…³æ³¨åº¦
- 40-59åˆ†ï¼šä¸€èˆ¬é‡è¦ï¼Œæ—¥å¸¸æ€§è´¢ç»æ–°é—»
- 20-39åˆ†ï¼šè¾ƒä½é‡è¦ï¼Œå½±å“æœ‰é™çš„æ¶ˆæ¯
- 0-19åˆ†ï¼šä¸é‡è¦ï¼Œå‡ ä¹æ— å¸‚åœºå½±å“

è¯·æ·±å…¥æ€è€ƒå¹¶åˆ†æï¼š
1. è¿™æ¡æ–°é—»æ¶‰åŠå“ªäº›å…³é”®è¦ç´ ï¼Ÿ
2. å¯¹è‚¡å¸‚ã€è¡Œä¸šã€ç»æµçš„æ½œåœ¨å½±å“æœ‰å¤šå¤§ï¼Ÿ
3. æ–°é—»çš„æ—¶æ•ˆæ€§å’Œæƒå¨æ€§å¦‚ä½•ï¼Ÿ
4. æ˜¯å¦æ¶‰åŠæ”¿ç­–ã€ç›‘ç®¡ã€é‡å¤§äº‹ä»¶ï¼Ÿ
5. å¯¹æŠ•èµ„è€…å†³ç­–çš„å‚è€ƒä»·å€¼æœ‰å¤šé«˜ï¼Ÿ

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{{
    "importance_score": åˆ†æ•°(0-100æ•´æ•°),
    "reasoning": "è¯¦ç»†çš„åˆ†ææ¨ç†è¿‡ç¨‹",
    "key_factors": ["å½±å“é‡è¦ç¨‹åº¦çš„å…³é”®å› ç´ 1", "å…³é”®å› ç´ 2", "å…³é”®å› ç´ 3"]
}}"""

        return prompt
    
    def _call_thinking_model(self, prompt: str) -> str:
        """è°ƒç”¨DeepSeekæ€è€ƒæ¨¡å‹"""
        try:
            deepseek_config = self.config.get("ai_analysis", {}).get("deepseek", {})
            
            # ä»é…ç½®æ–‡ä»¶è·å–æ€è€ƒæ¨¡å‹å‹å·ï¼Œé»˜è®¤ä¸ºdeepseek-reasoner
            thinking_model = deepseek_config.get("model", "deepseek-chat")
            
            logger.info(f"è°ƒç”¨æ¨¡å‹: {thinking_model}")
            
            # ä½¿ç”¨é…ç½®çš„æ€è€ƒæ¨¡å‹
            response = self.client.chat.completions.create(
                model=thinking_model,
                messages=[
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                max_tokens=deepseek_config.get("max_tokens", 2000),
                temperature=deepseek_config.get("temperature", 0.1)
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"è°ƒç”¨DeepSeekæ€è€ƒæ¨¡å‹å¤±è´¥: {e}")
            raise
    
    def _parse_importance_result(self, news_item: NewsItem, response: str) -> ImportanceResult:
        """è§£æé‡è¦ç¨‹åº¦åˆ†æç»“æœ"""
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                result_data = json.loads(json_str)
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œå°è¯•è§£æçº¯æ–‡æœ¬
                result_data = self._parse_text_result(response)
            
            # éªŒè¯å’Œæ¸…ç†æ•°æ®
            importance_score = int(result_data.get("importance_score", 50))
            importance_score = max(0, min(100, importance_score))  # ç¡®ä¿åœ¨0-100èŒƒå›´å†…
            
            reasoning = result_data.get("reasoning", "AIåˆ†æè¿‡ç¨‹")
            key_factors = result_data.get("key_factors", [])
            
            # ç¡®ä¿key_factorsæ˜¯åˆ—è¡¨
            if not isinstance(key_factors, list):
                key_factors = [str(key_factors)] if key_factors else ["æœªè¯†åˆ«å…³é”®å› ç´ "]
            
            # ä»é…ç½®æ–‡ä»¶è·å–æ¨¡å‹åç§°
            deepseek_config = self.config.get("ai_analysis", {}).get("deepseek", {})
            model_used = deepseek_config.get("thinking_model", "deepseek-reasoner")
            
            return ImportanceResult(
                news_id=news_item.id or f"news_{int(time.time())}",
                title=news_item.title,
                importance_score=importance_score,
                reasoning=reasoning,
                key_factors=key_factors[:5],  # æœ€å¤šä¿ç•™5ä¸ªå…³é”®å› ç´ 
                analysis_time=datetime.now().isoformat(),
                model_used=model_used
            )
            
        except Exception as e:
            logger.error(f"è§£æåˆ†æç»“æœå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤ç»“æœ
            return self._mock_analysis(news_item, error=True)
    
    def _parse_text_result(self, response: str) -> Dict:
        """è§£æçº¯æ–‡æœ¬æ ¼å¼çš„ç»“æœ"""
        result = {
            "importance_score": 50,
            "reasoning": response[:500],  # å–å‰500å­—ç¬¦ä½œä¸ºæ¨ç†è¿‡ç¨‹
            "key_factors": ["AIæ–‡æœ¬åˆ†æ"]
        }
        
        # å°è¯•ä»æ–‡æœ¬ä¸­æå–åˆ†æ•°
        score_patterns = [
            r'(\d+)åˆ†',
            r'è¯„åˆ†[ï¼š:]\s*(\d+)',
            r'é‡è¦ç¨‹åº¦[ï¼š:]\s*(\d+)',
            r'åˆ†æ•°[ï¼š:]\s*(\d+)'
        ]
        
        for pattern in score_patterns:
            match = re.search(pattern, response)
            if match:
                try:
                    score = int(match.group(1))
                    if 0 <= score <= 100:
                        result["importance_score"] = score
                        break
                except ValueError:
                    continue
        
        return result
    
    def _mock_analysis(self, news_item: NewsItem, error: bool = False) -> ImportanceResult:
        """æ¨¡æ‹Ÿåˆ†æç»“æœï¼ˆç”¨äºæµ‹è¯•æˆ–APIä¸å¯ç”¨æ—¶ï¼‰"""
        
        if error:
            score = 50
            reasoning = "ç”±äºAPIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è¯„åˆ†"
            factors = ["APIé”™è¯¯", "é»˜è®¤è¯„åˆ†"]
        else:
            # åŸºäºæ ‡é¢˜å…³é”®è¯ç®€å•è¯„åˆ†
            title = news_item.title.lower()
            score = 40  # åŸºç¡€åˆ†æ•°
            factors = []
            
            # é«˜é‡è¦æ€§å…³é”®è¯
            high_keywords = ["å¤®è¡Œ", "æ”¿ç­–", "ç›‘ç®¡", "é‡å¤§", "é‡è¦", "çªå‘", "ç´§æ€¥", "æš´è·Œ", "æš´æ¶¨", "åœç‰Œ", "IPO"]
            for keyword in high_keywords:
                if keyword in title:
                    score += 15
                    factors.append(f"åŒ…å«é«˜é‡è¦æ€§å…³é”®è¯: {keyword}")
            
            # ä¸­ç­‰é‡è¦æ€§å…³é”®è¯
            medium_keywords = ["è´¢æŠ¥", "ä¸šç»©", "å¢é•¿", "ä¸‹è·Œ", "ä¸Šæ¶¨", "åˆä½œ", "æŠ•èµ„", "æ”¶è´­"]
            for keyword in medium_keywords:
                if keyword in title:
                    score += 8
                    factors.append(f"åŒ…å«ä¸­ç­‰é‡è¦æ€§å…³é”®è¯: {keyword}")
            
            # ç¡®ä¿åˆ†æ•°åœ¨åˆç†èŒƒå›´å†…
            score = max(20, min(80, score))
            
            reasoning = f"åŸºäºæ ‡é¢˜å…³é”®è¯çš„æ¨¡æ‹Ÿåˆ†æï¼Œè¯„åˆ†ä¸º{score}åˆ†"
            
            if not factors:
                factors = ["æ ‡é¢˜åˆ†æ", "æ¨¡æ‹Ÿè¯„åˆ†"]
        
        return ImportanceResult(
            news_id=news_item.id or f"mock_{int(time.time())}",
            title=news_item.title,
            importance_score=score,
            reasoning=reasoning,
            key_factors=factors,
            analysis_time=datetime.now().isoformat(),
            model_used="mock_analyzer"
        )


if __name__ == '__main__':
    # æµ‹è¯•åŠŸèƒ½
    print("ğŸ” æµ‹è¯•æ–°é—»é‡è¦ç¨‹åº¦åˆ†æå™¨...")
    
    # åˆ›å»ºæµ‹è¯•æ–°é—»
    test_news = NewsItem(
        title="å¤®è¡Œå®£å¸ƒé™å‡†0.5ä¸ªç™¾åˆ†ç‚¹ï¼Œé‡Šæ”¾æµåŠ¨æ€§çº¦1ä¸‡äº¿å…ƒ",
        content="ä¸­å›½äººæ°‘é“¶è¡Œå†³å®šäº2024å¹´12æœˆ15æ—¥ä¸‹è°ƒé‡‘èæœºæ„å­˜æ¬¾å‡†å¤‡é‡‘ç‡0.5ä¸ªç™¾åˆ†ç‚¹ï¼Œæ­¤æ¬¡é™å‡†å°†é‡Šæ”¾é•¿æœŸèµ„é‡‘çº¦1ä¸‡äº¿å…ƒã€‚",
        source="å¤®è¡Œå®˜ç½‘",
        category="è´§å¸æ”¿ç­–"
    )
    
    analyzer = ImportanceAnalyzer()
    result = analyzer.analyze_importance(test_news)
    
    logger.info(f"ğŸ“° æ–°é—»: {result.title}")
    logger.info(f"ğŸ“Š é‡è¦ç¨‹åº¦: {result.importance_score} åˆ†")
    logger.info(f"ğŸ” å…³é”®å› ç´ : {', '.join(result.key_factors)}")
    logger.info(f"ğŸ’­ åˆ†ææ¨ç†: {result.reasoning}")
    logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {result.model_used}") 