#!/usr/bin/env python3
"""
AIåˆ†æåŠŸèƒ½æµ‹è¯•æ¨¡å—
æµ‹è¯•AIåˆ†æå™¨çš„å„é¡¹åŠŸèƒ½
"""

import os
import sys
import time
from datetime import datetime
from typing import Dict, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.ai_analyzer import AIAnalyzer
from src.utils.database import NewsItem, db_manager
from src.utils.logger import get_logger

logger = get_logger("test_ai_analysis")


class AIAnalysisTester:
    """AIåˆ†ææµ‹è¯•å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.analyzer = None
        self.results = {}
        self.mock_mode = False
        
    def test_analyzer_initialization(self) -> bool:
        """æµ‹è¯•åˆ†æå™¨åˆå§‹åŒ–"""
        print("ğŸ” æµ‹è¯•AIåˆ†æå™¨åˆå§‹åŒ–...")
        
        try:
            self.analyzer = AIAnalyzer()
            print("âœ… AIåˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # æ£€æŸ¥APIé…ç½®
            api_key = self.analyzer.config.get("ai_analysis", {}).get("deepseek", {}).get("api_key", "")
            if not api_key or api_key == "YOUR_DEEPSEEK_API_KEY":
                print("âš ï¸  æœªé…ç½®DeepSeek APIå¯†é’¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿåˆ†ææ¨¡å¼")
                self.mock_mode = True
            else:
                print("ğŸ”‘ å·²é…ç½®DeepSeek APIå¯†é’¥ï¼Œå°†ä½¿ç”¨çœŸå®åˆ†ææ¨¡å¼")
                self.mock_mode = False
                
            self.results["initialization"] = {
                "status": "success",
                "mock_mode": self.mock_mode
            }
            return True
            
        except Exception as e:
            print(f"âŒ AIåˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.results["initialization"] = {"status": "failed", "error": str(e)}
            return False

    def test_single_news_analysis(self) -> Dict[str, any]:
        """æµ‹è¯•å•æ¡æ–°é—»åˆ†æ"""
        print("\nğŸ¤– æµ‹è¯•å•æ¡æ–°é—»åˆ†æ")
        print("-" * 60)
        
        if not self.analyzer:
            print("âŒ åˆ†æå™¨æœªåˆå§‹åŒ–")
            return {"status": "failed", "error": "analyzer_not_initialized"}
            
        try:
            # åˆ›å»ºæµ‹è¯•æ–°é—»
            test_news = self._create_test_news()[0]  # å–ç¬¬ä¸€æ¡
            print(f"ğŸ” åˆ†ææµ‹è¯•æ–°é—»: {test_news.title[:50]}...")
            
            start_time = time.time()
            result = self.analyzer.analyze_single_news(test_news)
            end_time = time.time()
            
            analysis_time = end_time - start_time
            
            print(f"âœ… å•æ¡æ–°é—»åˆ†æå®Œæˆ")
            print(f"   åˆ†ææ—¶é—´: {analysis_time:.2f}ç§’")
            print(f"   å½±å“æ¿å—: {', '.join(result.affected_sectors[:3])}")
            print(f"   å½±å“è¯„åˆ†: {result.impact_score}/10")
            print(f"   æƒ…æ„Ÿå€¾å‘: {result.sentiment}")
            print(f"   åˆ†ææ¨¡å¼: {'æ¨¡æ‹Ÿ' if self.mock_mode else 'çœŸå®'}")
            
            test_result = {
                "status": "success",
                "analysis_time": analysis_time,
                "affected_sectors": result.affected_sectors,
                "impact_score": result.impact_score,
                "sentiment": result.sentiment,
                "mock_mode": self.mock_mode
            }
            
            self.results["single_analysis"] = test_result
            return test_result
            
        except Exception as e:
            print(f"âŒ å•æ¡æ–°é—»åˆ†æå¤±è´¥: {e}")
            result = {"status": "failed", "error": str(e)}
            self.results["single_analysis"] = result
            return result

    def test_batch_analysis(self, batch_size: int = 3) -> Dict[str, any]:
        """æµ‹è¯•æ‰¹é‡æ–°é—»åˆ†æ"""
        print(f"\nğŸ“Š æµ‹è¯•æ‰¹é‡æ–°é—»åˆ†æï¼ˆ{batch_size}æ¡ï¼‰")
        print("-" * 60)
        
        if not self.analyzer:
            print("âŒ åˆ†æå™¨æœªåˆå§‹åŒ–")
            return {"status": "failed", "error": "analyzer_not_initialized"}
            
        try:
            # è·å–æµ‹è¯•æ–°é—»
            test_news_list = self._get_test_news_for_analysis(batch_size)
            
            if not test_news_list:
                print("âŒ æ²¡æœ‰å¯åˆ†æçš„æ–°é—»")
                return {"status": "failed", "error": "no_news_available"}
            
            print(f"ğŸ” å¼€å§‹æ‰¹é‡åˆ†æ {len(test_news_list)} æ¡æ–°é—»...")
            
            start_time = time.time()
            results = self.analyzer.analyze_news_batch(test_news_list)
            end_time = time.time()
            
            analysis_time = end_time - start_time
            
            print(f"âœ… æ‰¹é‡åˆ†æå®Œæˆ")
            print(f"   åˆ†ææ•°é‡: {len(results)}")
            print(f"   æ€»ç”¨æ—¶: {analysis_time:.2f}ç§’")
            print(f"   å¹³å‡ç”¨æ—¶: {analysis_time/max(len(results),1):.2f}ç§’/æ¡")
            print(f"   åˆ†ææ¨¡å¼: {'æ¨¡æ‹Ÿ' if self.mock_mode else 'çœŸå®'}")
            
            # æ˜¾ç¤ºåˆ†æç»“æœç¤ºä¾‹
            if results:
                print(f"\nğŸ“‹ åˆ†æç»“æœç¤ºä¾‹:")
                for i, result in enumerate(results[:2]):
                    print(f"   {i+1}. å½±å“æ¿å—: {', '.join(result.affected_sectors[:3])}")
                    print(f"      å½±å“è¯„åˆ†: {result.impact_score}/10")
                    print(f"      æƒ…æ„Ÿå€¾å‘: {result.sentiment}")
            
            test_result = {
                "status": "success",
                "analyzed_count": len(results),
                "total_time": analysis_time,
                "average_time": analysis_time/max(len(results),1),
                "mock_mode": self.mock_mode,
                "sample_results": [
                    {
                        "affected_sectors": result.affected_sectors[:3],
                        "impact_score": result.impact_score,
                        "sentiment": result.sentiment
                    } for result in results[:2]
                ]
            }
            
            self.results["batch_analysis"] = test_result
            return test_result
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡åˆ†æå¤±è´¥: {e}")
            result = {"status": "failed", "error": str(e)}
            self.results["batch_analysis"] = result
            return result

    def test_analysis_quality(self) -> Dict[str, any]:
        """æµ‹è¯•åˆ†æè´¨é‡"""
        print("\nğŸ¯ æµ‹è¯•åˆ†æè´¨é‡")
        print("-" * 60)
        
        try:
            # åˆ›å»ºå…·æœ‰æ˜ç¡®ç‰¹å¾çš„æµ‹è¯•æ–°é—»
            quality_test_news = [
                NewsItem(
                    title="é“¶è¡Œè‚¡å¤§æ¶¨ï¼Œå»ºè®¾é“¶è¡Œæ¶¨åœï¼Œå·¥å•†é“¶è¡Œæ¶¨8%",
                    content="ä»Šæ—¥é“¶è¡Œæ¿å—è¡¨ç°å¼ºåŠ²ï¼Œå»ºè®¾é“¶è¡Œæ¶¨åœï¼Œå·¥å•†é“¶è¡Œæ¶¨8%ï¼Œé“¶è¡Œè‚¡æˆä¸ºå¸‚åœºç„¦ç‚¹ã€‚",
                    source="æµ‹è¯•æº",
                    category="é‡‘è",
                    publish_time=datetime.now()
                ),
                NewsItem(
                    title="ç§‘æŠ€è‚¡æš´è·Œï¼Œè…¾è®¯è·Œ5%ï¼Œé˜¿é‡Œå·´å·´è·Œ7%",
                    content="ç§‘æŠ€è‚¡ä»Šæ—¥é›†ä½“ä¸‹è·Œï¼Œè…¾è®¯æ§è‚¡è·Œ5%ï¼Œé˜¿é‡Œå·´å·´è·Œ7%ï¼ŒæŠ•èµ„è€…æ‹…å¿§ç›‘ç®¡æ”¿ç­–ã€‚",
                    source="æµ‹è¯•æº",
                    category="ç§‘æŠ€",
                    publish_time=datetime.now()
                )
            ]
            
            print(f"ğŸ” åˆ†æè´¨é‡æµ‹è¯•æ–°é—»...")
            
            results = []
            for news in quality_test_news:
                result = self.analyzer.analyze_single_news(news)
                results.append(result)
                
                print(f"   æ–°é—»: {news.title[:30]}...")
                print(f"   é¢„æœŸæ¿å—: {'é“¶è¡Œ' if 'é“¶è¡Œ' in news.title else 'ç§‘æŠ€'}")
                print(f"   åˆ†ææ¿å—: {', '.join(result.affected_sectors[:3])}")
                print(f"   é¢„æœŸæƒ…æ„Ÿ: {'ç§¯æ' if 'å¤§æ¶¨' in news.title else 'æ¶ˆæ'}")
                print(f"   åˆ†ææƒ…æ„Ÿ: {result.sentiment}")
                print()
            
            # è¯„ä¼°åˆ†æè´¨é‡
            quality_score = self._evaluate_analysis_quality(quality_test_news, results)
            
            print(f"ğŸ“Š åˆ†æè´¨é‡è¯„ä¼°:")
            print(f"   æ¿å—è¯†åˆ«å‡†ç¡®æ€§: {quality_score['sector_accuracy']:.1f}%")
            print(f"   æƒ…æ„Ÿè¯†åˆ«å‡†ç¡®æ€§: {quality_score['sentiment_accuracy']:.1f}%")
            print(f"   ç»¼åˆè´¨é‡è¯„åˆ†: {quality_score['overall_score']:.1f}%")
            
            test_result = {
                "status": "success",
                "quality_score": quality_score,
                "test_cases": len(quality_test_news),
                "mock_mode": self.mock_mode
            }
            
            self.results["analysis_quality"] = test_result
            return test_result
            
        except Exception as e:
            print(f"âŒ åˆ†æè´¨é‡æµ‹è¯•å¤±è´¥: {e}")
            result = {"status": "failed", "error": str(e)}
            self.results["analysis_quality"] = result
            return result

    def _get_test_news_for_analysis(self, limit: int) -> List[NewsItem]:
        """è·å–ç”¨äºåˆ†æçš„æµ‹è¯•æ–°é—»"""
        # é¦–å…ˆå°è¯•ä»æ•°æ®åº“è·å–
        from datetime import datetime, timedelta
        start_time = datetime.now() - timedelta(hours=24)
        recent_news = db_manager.get_news_items(limit=limit, start_time=start_time)
        
        if recent_news:
            print(f"   ä»æ•°æ®åº“è·å– {len(recent_news)} æ¡æœ€è¿‘æ–°é—»")
            return recent_news
        else:
            print(f"   æ•°æ®åº“ä¸­æ²¡æœ‰æ–°é—»ï¼Œåˆ›å»º {limit} æ¡æµ‹è¯•æ–°é—»")
            return self._create_test_news()[:limit]

    def _create_test_news(self) -> List[NewsItem]:
        """åˆ›å»ºæµ‹è¯•æ–°é—»æ•°æ®"""
        test_news = []
        
        test_data = [
            {
                "title": "Aè‚¡ä¸‰å¤§æŒ‡æ•°é›†ä½“ä¸Šæ¶¨ï¼Œæ²ªæŒ‡æ¶¨2.3%åˆ›æ–°é«˜",
                "content": "ä»Šæ—¥Aè‚¡å¸‚åœºè¡¨ç°å¼ºåŠ²ï¼Œä¸Šè¯æŒ‡æ•°æ¶¨2.3%ï¼Œæ·±è¯æˆæŒ‡æ¶¨2.8%ï¼Œåˆ›ä¸šæ¿æŒ‡æ¶¨3.1%ã€‚åˆ¸å•†ã€é“¶è¡Œæ¿å—é¢†æ¶¨ã€‚",
                "category": "è‚¡å¸‚è¡Œæƒ…"
            },
            {
                "title": "å¤®è¡Œé™å‡†é‡Šæ”¾æµåŠ¨æ€§ï¼Œé“¶è¡Œè‚¡åº”å£°ä¸Šæ¶¨",
                "content": "å¤®è¡Œå®£å¸ƒä¸‹è°ƒå­˜æ¬¾å‡†å¤‡é‡‘ç‡0.25ä¸ªç™¾åˆ†ç‚¹ï¼Œé‡Šæ”¾é•¿æœŸèµ„é‡‘çº¦5000äº¿å…ƒï¼Œé“¶è¡Œè‚¡é›†ä½“ä¸Šæ¶¨ã€‚",
                "category": "è´§å¸æ”¿ç­–"
            },
            {
                "title": "æ–°èƒ½æºæ±½è½¦äº§ä¸šæ”¿ç­–åˆ©å¥½ï¼Œç›¸å…³æ¦‚å¿µè‚¡å¤§æ¶¨",
                "content": "å›½å®¶å‘å¸ƒæ–°èƒ½æºæ±½è½¦äº§ä¸šå‘å±•æ”¿ç­–ï¼Œæ¯”äºšè¿ªã€ç‰¹æ–¯æ‹‰æ¦‚å¿µè‚¡å¤§æ¶¨ï¼Œæ¿å—æ¶¨å¹…è¶…è¿‡5%ã€‚",
                "category": "æ–°èƒ½æº"
            },
            {
                "title": "ç§‘æŠ€è‚¡é­é‡é‡æŒ«ï¼ŒèŠ¯ç‰‡æ¿å—è·Œå¹…å±…å‰",
                "content": "å—å›½é™…å½¢åŠ¿å½±å“ï¼Œç§‘æŠ€è‚¡ä»Šæ—¥å¤§å¹…ä¸‹è·Œï¼ŒèŠ¯ç‰‡æ¿å—è·Œå¹…å±…å‰ï¼Œä¸­èŠ¯å›½é™…è·Œè¶…8%ã€‚",
                "category": "ç§‘æŠ€"
            }
        ]
        
        for i, data in enumerate(test_data):
            news = NewsItem()
            news.title = data["title"]
            news.content = data["content"]
            news.source = "æµ‹è¯•æ•°æ®æº"
            news.category = data["category"]
            news.url = f"https://example.com/test/{i+1}"
            news.publish_time = datetime.now()
            news.keywords = ["Aè‚¡", "è´¢ç»"]
            test_news.append(news)
            
        return test_news

    def _evaluate_analysis_quality(self, test_news: List[NewsItem], results: List) -> Dict[str, float]:
        """è¯„ä¼°åˆ†æè´¨é‡"""
        sector_correct = 0
        sentiment_correct = 0
        total = len(test_news)
        
        for i, (news, result) in enumerate(zip(test_news, results)):
            # æ£€æŸ¥æ¿å—è¯†åˆ«
            if "é“¶è¡Œ" in news.title and "é“¶è¡Œ" in result.affected_sectors:
                sector_correct += 1
            elif "ç§‘æŠ€" in news.title and any(s in result.affected_sectors for s in ["ç§‘æŠ€", "äº’è”ç½‘", "è½¯ä»¶"]):
                sector_correct += 1
                
            # æ£€æŸ¥æƒ…æ„Ÿè¯†åˆ«
            if "å¤§æ¶¨" in news.title or "ä¸Šæ¶¨" in news.title:
                if result.sentiment in ["ç§¯æ", "æ­£é¢", "ä¹è§‚"]:
                    sentiment_correct += 1
            elif "æš´è·Œ" in news.title or "ä¸‹è·Œ" in news.title:
                if result.sentiment in ["æ¶ˆæ", "è´Ÿé¢", "æ‚²è§‚"]:
                    sentiment_correct += 1
        
        sector_accuracy = (sector_correct / total) * 100 if total > 0 else 0
        sentiment_accuracy = (sentiment_correct / total) * 100 if total > 0 else 0
        overall_score = (sector_accuracy + sentiment_accuracy) / 2
        
        return {
            "sector_accuracy": sector_accuracy,
            "sentiment_accuracy": sentiment_accuracy,
            "overall_score": overall_score
        }

    def run_all_tests(self) -> Dict[str, dict]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸ§ª AIåˆ†æåŠŸèƒ½æµ‹è¯•")
        print("=" * 80)
        
        # 1. æµ‹è¯•åˆå§‹åŒ–
        self.test_analyzer_initialization()
        
        # 2. æµ‹è¯•å•æ¡åˆ†æ
        self.test_single_news_analysis()
        
        # 3. æµ‹è¯•æ‰¹é‡åˆ†æ
        self.test_batch_analysis()
        
        # 4. æµ‹è¯•åˆ†æè´¨é‡
        self.test_analysis_quality()
        
        # æ˜¾ç¤ºæµ‹è¯•æ€»ç»“
        self.print_summary()
        
        return self.results

    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print("\n" + "=" * 80)
        print("ğŸ“‹ AIåˆ†ææµ‹è¯•æ€»ç»“")
        print("-" * 80)
        
        total_tests = len(self.results)
        successful_tests = len([r for r in self.results.values() if r.get("status") == "success"])
        
        print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"æˆåŠŸæ•°: {successful_tests}")
        print(f"å¤±è´¥æ•°: {total_tests - successful_tests}")
        print(f"æˆåŠŸç‡: {successful_tests/max(total_tests,1)*100:.1f}%")
        print(f"åˆ†ææ¨¡å¼: {'æ¨¡æ‹Ÿ' if self.mock_mode else 'çœŸå®'}")
        
        # æ˜¾ç¤ºå„é¡¹æµ‹è¯•ç»“æœ
        for test_name, result in self.results.items():
            status_icon = "âœ…" if result.get("status") == "success" else "âŒ"
            print(f"{status_icon} {test_name}")
            
            if result.get("status") == "success":
                if test_name == "batch_analysis":
                    count = result.get("analyzed_count", 0)
                    avg_time = result.get("average_time", 0)
                    print(f"   åˆ†æäº† {count} æ¡æ–°é—»ï¼Œå¹³å‡ {avg_time:.2f}ç§’/æ¡")
                elif test_name == "analysis_quality":
                    score = result.get("quality_score", {}).get("overall_score", 0)
                    print(f"   åˆ†æè´¨é‡è¯„åˆ†: {score:.1f}%")


def run_ai_analysis_tests():
    """è¿è¡ŒAIåˆ†ææµ‹è¯•çš„ä¸»å‡½æ•°"""
    tester = AIAnalysisTester()
    results = tester.run_all_tests()
    return results


if __name__ == "__main__":
    run_ai_analysis_tests() 