#!/usr/bin/env python3
"""
AIåˆ†æåŠŸèƒ½æµ‹è¯•æ¨¡å—
æµ‹è¯•AIåˆ†æå™¨çš„å„é¡¹åŠŸèƒ½
"""

import os
import sys
import time
from datetime import datetime
from typing import Dict, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.ai.ai_analyzer import AIAnalyzer
from src.utils.database import NewsItem, db_manager
from src.utils.logger import get_logger

logger = get_logger("test_ai_analysis")


class AIAnalysisTester:
    """AIåˆ†ææµ‹è¯•å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.analyzer = None
        self.results = {}
        self.mock_mode = False
        
    def test_analyzer_initialization(self) -> bool:
        """æµ‹è¯•åˆ†æå™¨åˆå§‹åŒ–"""
        print("ğŸ” æµ‹è¯•AIåˆ†æå™¨åˆå§‹åŒ–...")
        
        try:
            self.analyzer = AIAnalyzer()
            print("âœ… AIåˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # æ£€æŸ¥APIé…ç½®
            api_key = self.analyzer.config.get("ai_analysis", {}).get("deepseek", {}).get("api_key", "")
            if not api_key or api_key == "YOUR_DEEPSEEK_API_KEY":
                print("âš ï¸  æœªé…ç½®DeepSeek APIå¯†é’¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿåˆ†ææ¨¡å¼")
                self.mock_mode = True
            else:
                print("ğŸ”‘ å·²é…ç½®DeepSeek APIå¯†é’¥ï¼Œå°†ä½¿ç”¨çœŸå®åˆ†ææ¨¡å¼")
                self.mock_mode = False
                
            self.results["initialization"] = {
                "status": "success",
                "mock_mode": self.mock_mode
            }
            return True
            
        except Exception as e:
            print(f"âŒ AIåˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.results["initialization"] = {"status": "failed", "error": str(e)}
            return False

    def test_single_news_analysis(self) -> Dict[str, any]:
        """æµ‹è¯•å•æ¡æ–°é—»åˆ†æ"""
        print("\nğŸ¤– æµ‹è¯•å•æ¡æ–°é—»åˆ†æ")
        print("-" * 60)
        
        if not self.analyzer:
            print("âŒ åˆ†æå™¨æœªåˆå§‹åŒ–")
            return {"status": "failed", "error": "analyzer_not_initialized"}
            
        try:
            # åˆ›å»ºæµ‹è¯•æ–°é—»
            test_news = self._create_test_news()[0]  # å–ç¬¬ä¸€æ¡
            print(f"ğŸ” åˆ†ææµ‹è¯•æ–°é—»: {test_news.title[:50]}...")
            
            start_time = time.time()
            result = self.analyzer.analyze_single_news(test_news)
            end_time = time.time()
            
            analysis_time = end_time - start_time
            
            print(f"âœ… å•æ¡æ–°é—»åˆ†æå®Œæˆ")
            print(f"   åˆ†ææ—¶é—´: {analysis_time:.2f}ç§’")
            print(f"   å½±å“è¯„åˆ†: {result.impact_score}/100")
            print(f"   åˆ†ææ‘˜è¦: {result.summary[:50]}...")
            print(f"   åˆ†ææ¨¡å¼: {'çœŸå®' if not self.mock_mode else 'æ¨¡æ‹Ÿ'}")
            
            self.results["single_analysis"] = {
                "status": "success",
                "analysis_time": analysis_time,
                "impact_score": result.impact_score,
                "summary": result.summary,
                "mode": "real" if not self.mock_mode else "mock"
            }
            return self.results["single_analysis"]
            
        except Exception as e:
            print(f"âŒ å•æ¡æ–°é—»åˆ†æå¤±è´¥: {e}")
            result = {"status": "failed", "error": str(e)}
            self.results["single_analysis"] = result
            return result

    def test_batch_analysis(self, batch_size: int = 3) -> Dict[str, any]:
        """æµ‹è¯•æ‰¹é‡æ–°é—»åˆ†æ"""
        print(f"\nğŸ“Š æµ‹è¯•æ‰¹é‡æ–°é—»åˆ†æï¼ˆ{batch_size}æ¡ï¼‰")
        print("-" * 60)
        
        if not self.analyzer:
            print("âŒ åˆ†æå™¨æœªåˆå§‹åŒ–")
            return {"status": "failed", "error": "analyzer_not_initialized"}
            
        try:
            # è·å–æµ‹è¯•æ–°é—»
            test_news_list = self._get_test_news_for_analysis(batch_size)
            
            if not test_news_list:
                print("âŒ æ²¡æœ‰å¯åˆ†æçš„æ–°é—»")
                return {"status": "failed", "error": "no_news_available"}
            
            print(f"ğŸ” å¼€å§‹æ‰¹é‡åˆ†æ {len(test_news_list)} æ¡æ–°é—»...")
            
            start_time = time.time()
            results = self.analyzer.batch_analyze(test_news_list)
            end_time = time.time()
            
            analysis_time = end_time - start_time
            
            print(f"âœ… æ‰¹é‡åˆ†æå®Œæˆ")
            print(f"   åˆ†ææ•°é‡: {len(results)}")
            print(f"   æ€»ç”¨æ—¶: {analysis_time:.2f}ç§’")
            print(f"   å¹³å‡ç”¨æ—¶: {analysis_time/max(len(results),1):.2f}ç§’/æ¡")
            print(f"   åˆ†ææ¨¡å¼: {'æ¨¡æ‹Ÿ' if self.mock_mode else 'çœŸå®'}")
            
            # æ˜¾ç¤ºåˆ†æç»“æœç¤ºä¾‹
            if results:
                print(f"\nğŸ“‹ åˆ†æç»“æœç¤ºä¾‹:")
                for i, result in enumerate(results[:3], 1):
                    print(f"   {i}. å½±å“è¯„åˆ†: {result.impact_score}/100")
                    print(f"      æ‘˜è¦: {result.summary[:50]}...")
                    if i < 3:
                        print()
            
            test_result = {
                "status": "success",
                "analyzed_count": len(results),
                "total_time": analysis_time,
                "average_time": analysis_time/max(len(results),1),
                "mock_mode": self.mock_mode,
                "sample_results": [
                    {
                        "impact_score": result.impact_score,
                        "summary": result.summary[:50]
                    } for result in results[:2]
                ]
            }
            
            self.results["batch_analysis"] = test_result
            return test_result
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡åˆ†æå¤±è´¥: {e}")
            result = {"status": "failed", "error": str(e)}
            self.results["batch_analysis"] = result
            return result

    def test_analysis_quality(self) -> Dict:
        """æµ‹è¯•åˆ†æè´¨é‡"""
        print("ğŸ¯ æµ‹è¯•åˆ†æè´¨é‡")
        print("------------------------------------------------------------")
        
        try:
            print("ğŸ” æµ‹è¯•åˆ†æè´¨é‡...")
            
            # å®šä¹‰æµ‹è¯•ç”¨ä¾‹
            test_cases = [
                {
                    "news": NewsItem(
                        id="quality_test_1",
                        title="é“¶è¡Œè‚¡å¤§æ¶¨ï¼Œå»ºè®¾é“¶è¡Œæ¶¨åœï¼Œå·¥å•†é“¶è¡Œæ¶¨8%",
                        content="ä»Šæ—¥é“¶è¡Œæ¿å—å¤§å¹…ä¸Šæ¶¨ï¼Œå»ºè®¾é“¶è¡Œå¼ºåŠ¿æ¶¨åœï¼Œå·¥å•†é“¶è¡Œæ¶¨å¹…è¾¾8%ï¼Œé“¶è¡Œä¸šç»©è¶…é¢„æœŸã€‚",
                        source="æµ‹è¯•",
                        category="é“¶è¡Œ",
                        keywords=["é“¶è¡Œ", "å¤§æ¶¨", "æ¶¨åœ"]
                    ),
                    "expected_range": (60, 100)  # é¢„æœŸé«˜å½±å“è¯„åˆ†
                },
                {
                    "news": NewsItem(
                        id="quality_test_2", 
                        title="ç§‘æŠ€è‚¡æš´è·Œï¼Œè…¾è®¯è·Œ5%ï¼Œé˜¿é‡Œå·´å·´è·Œ7%",
                        content="ç§‘æŠ€è‚¡ä»Šæ—¥é­é‡é‡æŒ«ï¼Œè…¾è®¯æ§è‚¡è·Œ5%ï¼Œé˜¿é‡Œå·´å·´è·Œ7%ï¼ŒæŠ•èµ„è€…æ‹…å¿§ç›‘ç®¡æ”¿ç­–ã€‚",
                        source="æµ‹è¯•",
                        category="ç§‘æŠ€", 
                        keywords=["ç§‘æŠ€", "æš´è·Œ", "ä¸‹è·Œ"]
                    ),
                    "expected_range": (0, 40)  # é¢„æœŸä½å½±å“è¯„åˆ†
                }
            ]
            
            score_correct = 0
            total_tests = len(test_cases)
            
            for test_case in test_cases:
                news = test_case["news"]
                expected_min, expected_max = test_case["expected_range"]
                
                result = self.analyzer.analyze_single_news(news)
                
                print(f"   æ–°é—»: {news.title[:30]}...")
                print(f"   é¢„æœŸè¯„åˆ†èŒƒå›´: {expected_min}-{expected_max}")
                print(f"   å®é™…è¯„åˆ†: {result.impact_score}")
                print()
                
                # æ£€æŸ¥è¯„åˆ†æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
                if expected_min <= result.impact_score <= expected_max:
                    score_correct += 1
            
            score_accuracy = score_correct / total_tests * 100
            overall_quality = score_accuracy
            
            print(f"ğŸ“Š åˆ†æè´¨é‡è¯„ä¼°:")
            print(f"   è¯„åˆ†å‡†ç¡®æ€§: {score_accuracy:.1f}%")
            print(f"   ç»¼åˆè´¨é‡è¯„åˆ†: {overall_quality:.1f}%")
            
            self.results["analysis_quality"] = {
                "status": "success",
                "score_accuracy": score_accuracy,
                "overall_quality": overall_quality,
                "total_tests": total_tests
            }
            
            return self.results["analysis_quality"]
            
        except Exception as e:
            print(f"âŒ åˆ†æè´¨é‡æµ‹è¯•å¤±è´¥: {e}")
            self.results["analysis_quality"] = {
                "status": "error",
                "error": str(e)
            }
            return self.results["analysis_quality"]

    def _get_test_news_for_analysis(self, limit: int) -> List[NewsItem]:
        """è·å–ç”¨äºåˆ†æçš„æµ‹è¯•æ–°é—»"""
        # é¦–å…ˆå°è¯•ä»æ•°æ®åº“è·å–
        from datetime import datetime, timedelta
        start_time = datetime.now() - timedelta(hours=24)
        recent_news = db_manager.get_news_items(limit=limit, start_time=start_time)
        
        if recent_news:
            print(f"   ä»æ•°æ®åº“è·å– {len(recent_news)} æ¡æœ€è¿‘æ–°é—»")
            return recent_news
        else:
            print(f"   æ•°æ®åº“ä¸­æ²¡æœ‰æ–°é—»ï¼Œåˆ›å»º {limit} æ¡æµ‹è¯•æ–°é—»")
            return self._create_test_news()[:limit]

    def _create_test_news(self) -> List[NewsItem]:
        """åˆ›å»ºæµ‹è¯•æ–°é—»æ•°æ®"""
        test_news = []
        
        test_data = [
            {
                "title": "Aè‚¡ä¸‰å¤§æŒ‡æ•°é›†ä½“ä¸Šæ¶¨ï¼Œæ²ªæŒ‡æ¶¨2.3%åˆ›æ–°é«˜",
                "content": "ä»Šæ—¥Aè‚¡å¸‚åœºè¡¨ç°å¼ºåŠ²ï¼Œä¸Šè¯æŒ‡æ•°æ¶¨2.3%ï¼Œæ·±è¯æˆæŒ‡æ¶¨2.8%ï¼Œåˆ›ä¸šæ¿æŒ‡æ¶¨3.1%ã€‚åˆ¸å•†ã€é“¶è¡Œæ¿å—é¢†æ¶¨ã€‚",
                "category": "è‚¡å¸‚è¡Œæƒ…"
            },
            {
                "title": "å¤®è¡Œé™å‡†é‡Šæ”¾æµåŠ¨æ€§ï¼Œé“¶è¡Œè‚¡åº”å£°ä¸Šæ¶¨",
                "content": "å¤®è¡Œå®£å¸ƒä¸‹è°ƒå­˜æ¬¾å‡†å¤‡é‡‘ç‡0.25ä¸ªç™¾åˆ†ç‚¹ï¼Œé‡Šæ”¾é•¿æœŸèµ„é‡‘çº¦5000äº¿å…ƒï¼Œé“¶è¡Œè‚¡é›†ä½“ä¸Šæ¶¨ã€‚",
                "category": "è´§å¸æ”¿ç­–"
            },
            {
                "title": "æ–°èƒ½æºæ±½è½¦äº§ä¸šæ”¿ç­–åˆ©å¥½ï¼Œç›¸å…³æ¦‚å¿µè‚¡å¤§æ¶¨",
                "content": "å›½å®¶å‘å¸ƒæ–°èƒ½æºæ±½è½¦äº§ä¸šå‘å±•æ”¿ç­–ï¼Œæ¯”äºšè¿ªã€ç‰¹æ–¯æ‹‰æ¦‚å¿µè‚¡å¤§æ¶¨ï¼Œæ¿å—æ¶¨å¹…è¶…è¿‡5%ã€‚",
                "category": "æ–°èƒ½æº"
            },
            {
                "title": "ç§‘æŠ€è‚¡é­é‡é‡æŒ«ï¼ŒèŠ¯ç‰‡æ¿å—è·Œå¹…å±…å‰",
                "content": "å—å›½é™…å½¢åŠ¿å½±å“ï¼Œç§‘æŠ€è‚¡ä»Šæ—¥å¤§å¹…ä¸‹è·Œï¼ŒèŠ¯ç‰‡æ¿å—è·Œå¹…å±…å‰ï¼Œä¸­èŠ¯å›½é™…è·Œè¶…8%ã€‚",
                "category": "ç§‘æŠ€"
            }
        ]
        
        for i, data in enumerate(test_data):
            news = NewsItem()
            news.title = data["title"]
            news.content = data["content"]
            news.source = "æµ‹è¯•æ•°æ®æº"
            news.category = data["category"]
            news.url = f"https://example.com/test/{i+1}"
            news.publish_time = datetime.now()
            news.keywords = ["Aè‚¡", "è´¢ç»"]
            test_news.append(news)
            
        return test_news

    def run_all_tests(self) -> Dict[str, dict]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸ§ª AIåˆ†æåŠŸèƒ½æµ‹è¯•")
        print("=" * 80)
        
        # 1. æµ‹è¯•åˆå§‹åŒ–
        self.test_analyzer_initialization()
        
        # 2. æµ‹è¯•å•æ¡åˆ†æ
        self.test_single_news_analysis()
        
        # 3. æµ‹è¯•æ‰¹é‡åˆ†æ
        self.test_batch_analysis()
        
        # 4. æµ‹è¯•åˆ†æè´¨é‡
        self.test_analysis_quality()
        
        # æ˜¾ç¤ºæµ‹è¯•æ€»ç»“
        self.print_summary()
        
        return self.results

    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print("\n" + "=" * 80)
        print("ğŸ“‹ AIåˆ†ææµ‹è¯•æ€»ç»“")
        print("-" * 80)
        
        total_tests = len(self.results)
        successful_tests = len([r for r in self.results.values() if r.get("status") == "success"])
        
        print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"æˆåŠŸæ•°: {successful_tests}")
        print(f"å¤±è´¥æ•°: {total_tests - successful_tests}")
        print(f"æˆåŠŸç‡: {successful_tests/max(total_tests,1)*100:.1f}%")
        print(f"åˆ†ææ¨¡å¼: {'æ¨¡æ‹Ÿ' if self.mock_mode else 'çœŸå®'}")
        
        # æ˜¾ç¤ºå„é¡¹æµ‹è¯•ç»“æœ
        for test_name, result in self.results.items():
            status_icon = "âœ…" if result.get("status") == "success" else "âŒ"
            print(f"{status_icon} {test_name}")
            
            if result.get("status") == "success":
                if test_name == "batch_analysis":
                    count = result.get("analyzed_count", 0)
                    avg_time = result.get("average_time", 0)
                    print(f"   åˆ†æäº† {count} æ¡æ–°é—»ï¼Œå¹³å‡ {avg_time:.2f}ç§’/æ¡")
                elif test_name == "analysis_quality":
                    score = result.get("quality_score", {}).get("overall_score", 0)
                    print(f"   åˆ†æè´¨é‡è¯„åˆ†: {score:.1f}%")


def run_ai_analysis_tests():
    """è¿è¡ŒAIåˆ†ææµ‹è¯•çš„ä¸»å‡½æ•°"""
    tester = AIAnalysisTester()
    results = tester.run_all_tests()
    return results


if __name__ == "__main__":
    run_ai_analysis_tests() 